# NeuroFun
- - -
Основная задача проекта: разработка обучаемой нейросетевой модели для генерации анекдотов с простым пользовательским интерфейсом.
## Стек технологий
- - -
|||
| --- | --- |
|[![Keras](https://keras.io/img/logo-small.png)](https://keras.io/about/)|Открытая нейросетевая библиотека,  представляет собой надстройку над фреймворками Deeplearning4j, TensorFlow и Theano. Нацелена на оперативную работу с сетями глубинного обучения, при этом спроектирована так, чтобы быть компактной, модульной и расширяемой||
|[![TensorFlow2](https://www.gstatic.com/devrel-devsite/prod/v0a30303ec7b067b5f3ae9ccc0662a5464fa8a5fb796392acd97bcfd40590684c/tensorflow/images/lockup.svg)](https://www.tensorflow.org/)|Открытая программная библиотека для машинного обучения, разработанная компанией Google для решения задач построения и тренировки нейронной сети с целью автоматического нахождения и классификации образов, достигая качества человеческого восприятия||
|[![NumPy](https://numpy.org/images/logos/numpy.svg)](https://keras.io/about/)|Библиотека с поддержкой многомерных массивов (включая матрицы) и высокоуровневых математических функций, предназначенных для работы с многомерными массивами.||
|[Tkinter](https://wiki.python.org/moin/TkInter)|Кросс-платформенная событийно-ориентированная графическая библиотека.||
|||||

## Установка
---
Для запуска скрипта необходима установка всех библиотек, перечисленных в прошлом разделе. 
##### 1. Требования к совместимости Keras:
- Python 3.5–3.8
- Ubuntu 16.04 or later
- Windows 7 or later
- macOS 10.12.6 (Sierra) or later.

##### 2. Установка Keras:
Для установки Keras достаточно установить TensorFlow 2. Рекомендуется обновить pip до последней версии.

    pip install --upgrade pip
    pip install tensorflow

## Презентация алгоритма
- - -
##### 1. Обучение модели:
Для обучения рекомендуется использовать датасет из анекдотов схожей структуры, разделенных одним разделителем: файл расширения .txt в кодировке UTF-8 размером не менее 500 килобайт. Модель применима для обучения на основе других текстов (например, стихотворений). Особенности алгоритма представлены списком:
1. Текст приводится к нижнему регистру. Лемматизация/стемминг не используются в предобработке датасета.
2. Токенизация посимвольная.
3. Для (де-)векторизации используются словари токен-индекс и индекс-токен.
4. Наборы X, Y для обучения построены по логике смещения целевой последовательности на символ вперед.

Все параметры, в том числе имена файлов, настраиваются в выделенном соответствующим комментарием блоке кода.
##### 2. Загрузка модели:
При каждом запуске скрипта алгоритм первоначально пытается загрузить модель из файла .h5. Если файл с указанным в настройках названием не найден -- модель будет обучена заново. Графический интерфейс запускается после получения обученной модели (любым способом).
##### 3. Генерация анекдота:
Спроектированная модель хорошо запоминает используемую в обучающем наборе структуру. При генерации она выполняет предсказания по одному токену, начиная с фиксированного семени "а". После девекторизации и получения выходной строки выполняется срез по разделителю между анекдотами из обучающего набора так, чтобы первый и последний анекдот были отброшены. По этой причине рекомендуется использовать out_len не менее 200 (значение может варьироваться в зависимости от используемого датасета).
## TODO: проблемы и пути развития
- - -
Основные недостатки текущей версии системы: присутствие несуществующих слов в сгенерированном анекдоте; абсурдность большинства генераций. Для обоих проблем актуальны общие способы решения:

- Увеличение объема датасета. При достаточном наборе слов нейросеть лучше запомнит основные паттерны словообразования и пунктуации.
- Увеличение типизированности датасета. Подразумевается удаление заведомо нежелательных обучающих примеров (анекдоты с имитацией акцента или речевых дефектов, а также с повторением одинаковых слов подряд), а также использование анекдотов одной структуры или тематики.
- Настройка модели в сторону увеличения числа рассматриваемых параметров.

Перечисленные пути развития подразумевают рост требований к вычислительным ресурсам. Ввиду этого не будет лишним рассмотреть альтернативные способы повышения качества: например, разработка или использование готовых средств исправления опечаток.

